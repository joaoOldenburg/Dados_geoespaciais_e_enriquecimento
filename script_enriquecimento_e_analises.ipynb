{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Já fiz o uso de arquivos deltas no databricks, porém não consegui importar\n",
        "no colab. Tentei por 30 minutos, ocorreram erros, decidi não focar nisso devido ao tempo que tenho para dedicar.\n",
        "\n",
        "Farei como se fossem vários parquets numa pasta e quisesse ler todos\n"
      ],
      "metadata": {
        "id": "ufBECFGWg0Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dataset possui as seguintes colunas: created_at (unix timestamp de quando a requisição foi recebida), publisher (string, uuid identificando o local onde o usuário estava navegando), event_type (string, identifica o tipo requisição), ip (string, semi anonimizado), user_id (string, uuid identificando o usuário), geo_lat (double, latitude onde o usuário estava fisicamente), geo_lon (double, longiture onde o usuário estava fisicamente), geo_country (string, país da localização latitude-longitude), geo_region (string, estado da localização latitude-longitude), geo_city (string, cidade da localização latitude-longitude)."
      ],
      "metadata": {
        "id": "FRnbMDu-kCFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import geopandas as gpd\n",
        "import plotly.express as px\n",
        "from glob import glob\n",
        "from shapely.geometry import Point\n"
      ],
      "metadata": {
        "id": "y9XpFxAygPxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bases descontos\n",
        "df_paths = glob('/content/drive/MyDrive/Caze_zedia/format_1/*')\n",
        "\n",
        "df_list = [pd.read_parquet(table)\n",
        "               for table in df_paths]\n",
        "\n",
        "# concatenando historico\n",
        "df = pd.concat(df_list).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "t5n18PmmgSxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bases IBGE de informações de renda\n",
        "df_ibge = pd.read_excel(\n",
        "    '/content/drive/MyDrive/Caze_zedia/ResponsavelRenda_PR.xls',\n",
        "     usecols=['Cod_setor', 'Situacao_setor', 'V001', 'V002', 'V003',\n",
        "         'V004', 'V005', 'V006', 'V007', 'V008', 'V009', 'V021'])\n",
        "\n",
        "# Lendo arquivos shapefile do ibge\n",
        "setores = gpd.read_file(\"/content/drive/MyDrive/Caze_zedia/41SEE250GC_SIR.shp\")\n"
      ],
      "metadata": {
        "id": "39Zc1dC2lAmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entendendo se as colunas vieram corretamente (nome e formato)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "wSVbtJPgjnp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amostra de dados para ficar no radar\n",
        "\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "7y0bdXINnSIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entendendo a quantidades de labels por coluna para possíveis agrupamentos\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "8Z7470-Ejsy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando distribuições dos tipos de requisição no server\n",
        "df['event_type'].value_counts()"
      ],
      "metadata": {
        "id": "Nsh8Dewv2Wsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando distribuições dos tipos de requisição no server\n",
        "df['event_type'].value_counts()\n",
        "\n",
        "# Visualização da diferença muito alta de frequência\n",
        "fig = px.histogram(df,\n",
        "                   x=\"event_type\",\n",
        "                   title='Distribuição de frequência de requisições')\n",
        "fig.update_layout(\n",
        "        yaxis_title=\"frequência\",\n",
        "        xaxis_title=\"Requisição\",\n",
        "        template=\"simple_white\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "MrA1dgWUm_Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a distribuição de frequências por estados\n",
        "# Algumas letras e número no meio dos estados - 11, 10 e N\n",
        "# Interessante aderencia no PR e SC, poém não no RS\n",
        "\n",
        "frequency_df = df['geo_region'].value_counts().reset_index()\n",
        "frequency_df.columns = ['geo_region', 'frequency']\n",
        "\n",
        "# Ordenar pelo valor de frequência - Visto no GPT como fazer\n",
        "frequency_df = frequency_df.sort_values(by='frequency', ascending=False)\n",
        "\n",
        "# Criar o histograma com as categorias ordenadas\n",
        "fig = px.histogram(\n",
        "    frequency_df,\n",
        "    x='geo_region',\n",
        "    y='frequency',\n",
        "    title='Distribuição de frequência de geo regions',\n",
        "    category_orders={'geo_region': frequency_df['geo_region']}\n",
        ")\n",
        "\n",
        "# Atualizar o layout do gráfico\n",
        "fig.update_layout(\n",
        "    yaxis_title='Frequência',\n",
        "    xaxis_title='Requisição',\n",
        "    template='simple_white'\n",
        ")\n",
        "\n",
        "# Exibir o gráfico\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "gz0pPnP9xdoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupando por data e quantidade de requisicoes com contagem\n",
        "df_grouped = df.groupby(by=['created_at', 'event_type'])['event_type']\\\n",
        "  .count().reset_index(name='count')\n",
        "\n",
        "# Verificando séries temporais das quantidades de requisições recebidas\n",
        "df_grouped = df_grouped.sort_values(by='created_at')\n",
        "\n",
        "for requisicao in df_grouped['event_type'].unique():\n",
        "\n",
        "    df_plot = df_grouped.loc[df_grouped['event_type'] == requisicao]\n",
        "\n",
        "    # Serie temporaç\n",
        "    fig = px.line(\n",
        "        df_plot,\n",
        "        x='created_at', y='count',\n",
        "        color='event_type',\n",
        "        title=f'Quantidade recebidas | Requisicao = {requisicao}')\n",
        "\n",
        "    fig.update_layout(\n",
        "        yaxis_title=\"Qtd de requisições\",\n",
        "        xaxis_title=\"Tempo\",\n",
        "        template=\"simple_white\")\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "FuRI22y9o2-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As séries não parecem orgânicas, estão estranhas então irei conferir\n",
        "# A série poll-answer foi escolhida pois é uma constante, logo fácil de\n",
        "# conferir. As séreis foram plotadas corretamente\n",
        "\n",
        "\n",
        "df.loc[df['event_type'] == 'poll-answer']"
      ],
      "metadata": {
        "id": "XvYzGg5Wr-Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entendendo se o somatório das requisições segue um padrão mais orgânico\n",
        "# É esperado que reproduza um sinal parecido com as dos primeiros sinais da\n",
        "# célula anterior - Devido a freuência muito maior\n",
        "# Agrupando por data e contando requisições\n",
        "df_grouped = df.groupby(by=['created_at'])['event_type']\\\n",
        "  .count().reset_index()\n",
        "\n",
        "# Verificando séries temporais das quantidades de requisições recebidas\n",
        "df_grouped = df_grouped.sort_values(by='created_at')\n",
        "\n",
        "# Serie temporal\n",
        "fig = px.line(\n",
        "    df_grouped,\n",
        "    x='created_at', y='event_type',\n",
        "    title=f'Quantidade de requisições recebidas')\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title=\"Qtd de requisições\",\n",
        "    xaxis_title=\"Tempo\",\n",
        "    template=\"simple_white\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7eF3BwBrzF4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Os resultados mostraram que existem geo regiões que não são estados\n",
        "# Recurrent-ping escolhido pela maior frequência\n",
        "\n",
        "# Os estados que possuem relevância no número e requisições\n",
        "# seguem o mesmo padrão já visto no agregado do tipo de requisição\n",
        "\n",
        "# Também entendendo se existia algum estado que poderia ser\n",
        "# um servidor de teste sujando a sérei, pois as vzes apenas\n",
        "# uma série está sujando a série e o restande tem uma\n",
        "# possibilidade maior de previsão\n",
        "\n",
        "\n",
        "df_recurrent_ping = df.loc[df['event_type'] == 'recurrent-ping']\n",
        "\n",
        "# Gerado pelo GPT - não lembrava como agrupar dois eventos\n",
        "df_grouped = (\n",
        "    df_recurrent_ping.groupby(\n",
        "        ['created_at', 'event_type', 'geo_region']\n",
        "    ).size()  # Usando .size() para contar as aparições\n",
        "    .reset_index(name='count')  # Renomeando a coluna de contagem\n",
        ")\n",
        "\n",
        "# Verificando séries temporais das quantidades de requisições recebidas\n",
        "df_grouped = df_grouped.sort_values(by='created_at')\n",
        "\n",
        "for estado in df_grouped['geo_region'].unique():\n",
        "\n",
        "    df_plot = df_grouped.loc[df_grouped['geo_region'] == estado]\n",
        "\n",
        "    # Serie temporaç\n",
        "    fig = px.line(\n",
        "        df_plot,\n",
        "        x='created_at', y='count',\n",
        "        color='event_type',\n",
        "        title=f'Quantidade recebidas | Estado = {estado}')\n",
        "\n",
        "    fig.update_layout(\n",
        "        yaxis_title=\"Qtd de requisições\",\n",
        "        xaxis_title=\"Tempo\",\n",
        "        template=\"simple_white\")\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "D8HydN6Q0cYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando as séries dos locais de navegação\n",
        "# recurrent-ping escolhido pela maior frequência\n",
        "# Entendendo se algum publisher pode estar sujando\n",
        "\n",
        "df_recurrent_ping = df.loc[df['event_type'] == 'recurrent-ping']\n",
        "\n",
        "# Gerado pelo GPT - não lembrava como agrupar dois eventos\n",
        "df_grouped = (\n",
        "    df_recurrent_ping.groupby(\n",
        "        ['created_at', 'event_type', 'publisher']\n",
        "    ).size()  # Usando .size() para contar as aparições\n",
        "    .reset_index(name='count')  # Renomeando a coluna de contagem\n",
        ")\n",
        "\n",
        "# Verificando séries temporais das quantidades de requisições recebidas\n",
        "df_grouped = df_grouped.sort_values(by='created_at')\n",
        "\n",
        "for publisher in df_grouped['publisher'].unique():\n",
        "\n",
        "    df_plot = df_grouped.loc[df_grouped['publisher'] == publisher]\n",
        "\n",
        "    # Serie temporaç\n",
        "    fig = px.line(\n",
        "        df_plot,\n",
        "        x='created_at', y='count',\n",
        "        color='event_type',\n",
        "        title=f'Quantidade recebidas | publisher = {publisher}')\n",
        "\n",
        "    fig.update_layout(\n",
        "        yaxis_title=\"Qtd de requisições\",\n",
        "        xaxis_title=\"Tempo\",\n",
        "        template=\"simple_white\")\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "yXSNqz7c_Y1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apenas um estado gerou a requisição poll-answer\n",
        "\n",
        "df_poll_answer = df.loc[df['event_type'] == 'poll-answer']\n",
        "\n",
        "# Gerado pelo GPT - não lembrava como agrupar dois eventos\n",
        "df_grouped = (\n",
        "    df_poll_answer.groupby(\n",
        "        ['created_at', 'event_type', 'geo_region']\n",
        "    ).size()  # Usando .size() para contar as aparições\n",
        "    .reset_index(name='count')  # Renomeando a coluna de contagem\n",
        ")\n",
        "\n",
        "# Verificando séries temporais das quantidades de requisições recebidas\n",
        "df_grouped = df_grouped.sort_values(by='created_at')\n",
        "\n",
        "for estado in df_grouped['geo_region'].unique():\n",
        "\n",
        "    df_plot = df_grouped.loc[df_grouped['geo_region'] == estado]\n",
        "\n",
        "    # Serie temporaç\n",
        "    fig = px.line(\n",
        "        df_plot,\n",
        "        x='created_at', y='count',\n",
        "        color='event_type',\n",
        "        title=f'Quantidade recebidas | Estado = {estado}')\n",
        "\n",
        "    fig.update_layout(\n",
        "        yaxis_title=\"Qtd de requisições\",\n",
        "        xaxis_title=\"Tempo\",\n",
        "        template=\"simple_white\")\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "-LyN5jhL2dMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ontem o trabalho seguiu mais reflexivo de entendimento das bases, em um momento\n",
        "menos \"produtivo\" e mais criativo.\n",
        "\n",
        "Devido as séries com aparência não orgânica e baixo entendimento do negócio nos\n",
        "picos de requisições surgiram ideias, porém com baixa aplicabilidade real.\n",
        "Das ideias que surgiram: é possível entender anomalias ou em caso de\n",
        "picos com causas conhecidos e desejados, verificar uplift dessas causas com a ideia de prever demandas futuras para preparo de servidores e afins.\n",
        "\n",
        "Porém, para ser mais realista, algo que vai ser útil idependentemente dos tipos de dados é o enriquecimento com dados de renda dos setores censitários das requisições, visto que existe o produto \"anuncio\" e ele deve levar caracteristica de renda na sua distribuição.\n"
      ],
      "metadata": {
        "id": "iIraB4sXDra7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário para identificação -  Retirado da documentação do ibge\n",
        "dicionario = {'V001': 'meio salario', 'V002': 'meio a 1 salario',\n",
        "              'V003': '1 a 2 salarios', 'V004': '2 a 3 salarios',\n",
        "              'V005': '3 a 5 salarios', 'V006': '5 a 10 salarios',\n",
        "              'V007': '10 a 15 salarios', 'V008': '15 a 20 salarios',\n",
        "              'V009': 'maior que 20 salarios', 'V021': 'total_responsaveis',\n",
        "              'Cod_setor': 'setor_censitario'}\n",
        "\n",
        "df_ibge = df_ibge.rename(columns=dicionario)\n",
        "\n",
        "result = df_ibge.dropna().drop_duplicates()\n",
        "result = result.reset_index(drop=True)\n",
        "\n",
        "# convertendo para numérico\n",
        "result[['meio salario', 'meio a 1 salario', '1 a 2 salarios',\n",
        "        '2 a 3 salarios', '3 a 5 salarios', '5 a 10 salarios',\n",
        "        '10 a 15 salarios', '15 a 20 salarios', 'maior que 20 salarios',\n",
        "        'total_responsaveis']] =\\\n",
        "        pd.to_numeric(\n",
        "        result[['meio salario', 'meio a 1 salario', '1 a 2 salarios',\n",
        "                '2 a 3 salarios', '3 a 5 salarios', '5 a 10 salarios',\n",
        "                '10 a 15 salarios', '15 a 20 salarios',\n",
        "                'maior que 20 salarios',\n",
        "                'total_responsaveis']].stack(), errors='coerce').unstack()\n",
        "\n",
        "# Normaliza para permitir comparações da participação da faixa de renda no\n",
        "# no total, e poder somar para chegar na média de salários\n",
        "result['meio salario'] =\\\n",
        "    result['meio salario'] * 0.5 / result['total_responsaveis']\n",
        "result['meio a 1 salario'] =\\\n",
        "    result['meio a 1 salario'] * 0.75 / result['total_responsaveis']\n",
        "result['1 a 2 salarios'] =\\\n",
        "    result['1 a 2 salarios'] * 1.5 / result['total_responsaveis']\n",
        "result['2 a 3 salarios'] =\\\n",
        "    result['2 a 3 salarios'] * 2.5 / result['total_responsaveis']\n",
        "result['3 a 5 salarios'] =\\\n",
        "    result['3 a 5 salarios'] * 3.5 / result['total_responsaveis']\n",
        "result['5 a 10 salarios'] =\\\n",
        "    result['5 a 10 salarios'] * 7.5 / result['total_responsaveis']\n",
        "result['10 a 15 salarios'] =\\\n",
        "    result['10 a 15 salarios'] * 12.5 / result['total_responsaveis']\n",
        "result['15 a 20 salarios'] =\\\n",
        "    result['15 a 20 salarios'] * 17.5 / result['total_responsaveis']\n",
        "result['maior que 20 salarios'] =\\\n",
        "    result['maior que 20 salarios'] * 20 / result['total_responsaveis']\n",
        "\n",
        "# Para calcular a renda média\n",
        "result['renda_media'] = (result['meio salario'] + result['meio a 1 salario'] +\n",
        "                         result['1 a 2 salarios'] + result['2 a 3 salarios'] +\n",
        "                         result['3 a 5 salarios'] + result['5 a 10 salarios'] +\n",
        "                         result['10 a 15 salarios'] + result['15 a 20 salarios'] +\n",
        "                         result['maior que 20 salarios'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tgyg8qQJD9Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setores.info()"
      ],
      "metadata": {
        "id": "IYLmFZtr1e8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unindo tabelas IBGE\n",
        "result['setor_censitario'] = result['setor_censitario'].astype(str)\n",
        "df_ibge_merged = result.merge(\n",
        "    setores, left_on='setor_censitario', right_on='CD_GEOCODI', how='left')\n",
        "\n",
        "# Deixando apenas paraná, foi escolhido pois é o estado onde existe o maior\n",
        "# número de requisições\n",
        "\n",
        "df_pr = df.loc[df['geo_region'] == 'PR'].copy()"
      ],
      "metadata": {
        "id": "xPw-eP5uorT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptado do GPT de outro código meu\n",
        "# Converte latitude e longitude para objetos de ponto\n",
        "df_pr['geometry'] = df_pr.apply(\n",
        "    lambda row: Point(row['geo_lon'], row['geo_lat']), axis=1)\n",
        "\n",
        "# Converte para um GeoDataFrame\n",
        "# com o mesmo sistema de coordenadas do setor censitário\n",
        "gdf_coords = gpd.GeoDataFrame(df_pr, geometry='geometry', crs=\"EPSG:4674\")"
      ],
      "metadata": {
        "id": "eo8x_cSmv6tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fw5GnvR4D7zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a junção espacial\n",
        "merged_gdf = gpd.sjoin(gdf_coords, setores, how=\"inner\", predicate=\"within\")"
      ],
      "metadata": {
        "id": "vABHbWlC5kb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_gdf.info()"
      ],
      "metadata": {
        "id": "uUhlcrfC5xAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pronto agora temos mais informações e podemos clusterizar, existe outras maneiras de enriquecer, como quanitdade de homens e mulheres para segmentação de anúncios, entre outras possibilidades."
      ],
      "metadata": {
        "id": "7zBriTgh8ova"
      }
    }
  ]
}